{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b1451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms, io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f608b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### modified resnets are done\n",
    "\n",
    "class ModResNet18(models.resnet.ResNet):\n",
    "    def __init__(self, out_features=10, custom_classifier=False):\n",
    "        super(ModResNet18, self).__init__(models.resnet.BasicBlock, [2, 2, 2, 2], num_classes=out_features)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7, 7),\n",
    "                               stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        if custom_classifier:\n",
    "            classifier = Classifier(self.fc.in_features, out_features)\n",
    "            self.fc = classifier\n",
    "        \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=out_features, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.tanh(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d485d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAINING\n",
    "class ANNTrainer:\n",
    "    def __init__(self, name, model, train_loader, validation_loader, writer,\n",
    "                 criterion, device='cpu', lr=1e-2):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.validation_loader = validation_loader\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "        torch.save(self.model.state_dict(),\n",
    "                   '{}_initial.pt'.format(self.name))\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        self.writer = writer\n",
    "    \n",
    "    def find_lr(self, init_value=1e-8, final_value=1):\n",
    "        num = len(self.train_loader) - 1\n",
    "        mult = (final_value / init_value) ** (1/num)\n",
    "        lr = init_value\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            X, y = data\n",
    "            if self.device == 'cuda':\n",
    "                X = X.to('cuda')\n",
    "                y = y.to('cuda')\n",
    "            \n",
    "            y_pred = self.model.forward(X)\n",
    "            loss = self.criterion(y_pred, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            self.writer.add_scalar('Lr loss', loss.item(), np.log10(lr)*1000)\n",
    "            \n",
    "            lr *= mult\n",
    "            self.optimizer.param_groups[0]['lr'] = lr\n",
    "            \n",
    "        self.model.load_state_dict(torch.load('{}_initial.pt'.format(self.name)))\n",
    "        \n",
    "    def assign_lr(self, lr):\n",
    "        self.optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "    def train(self, epochs, lr_scheduler=False, save_epoch=10):\n",
    "        if lr_scheduler:\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, epochs//2)\n",
    "        \n",
    "        for e in trange(epochs):\n",
    "            self.model.train()\n",
    "            ls = self.train_epoch()\n",
    "            if lr_scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            avg_loss = np.mean(ls)\n",
    "            \n",
    "            self.model.eval()\n",
    "            avg_vloss = 0\n",
    "            for i, data in enumerate(self.validation_loader):\n",
    "                X, y = data\n",
    "                if self.device == 'cuda':\n",
    "                    X = X.to('cuda')\n",
    "                    y = y.to('cuda')\n",
    "                \n",
    "                y_pred = self.model.forward(X)\n",
    "                vloss = self.criterion(y_pred, y)\n",
    "                \n",
    "                avg_vloss += vloss.item()\n",
    "                \n",
    "            avg_vloss /= i + 1\n",
    "            if e == 0:\n",
    "                best_vloss = avg_vloss\n",
    "            \n",
    "            if avg_vloss < best_vloss:\n",
    "                torch.save(self.model.state_dict(),\n",
    "                           '{}_state_dict.pt'.format(self.name))\n",
    "                \n",
    "            if (e+1)%save_epoch == 0:\n",
    "                torch.save(self.model.state_dict(),\n",
    "                           '{}_epoch{}_state_dict.pt'.format(self.name, e+1))\n",
    "                \n",
    "            self.writer.add_scalars('Loss',\n",
    "                                    {'train': avg_loss,\n",
    "                                     'validation': avg_vloss}, e)\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        running_loss = []\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            X, y = data\n",
    "            if self.device == 'cuda':\n",
    "                X = X.to('cuda')\n",
    "                y = y.to('cuda')\n",
    "            \n",
    "            y_pred = self.model.forward(X)\n",
    "            loss = self.criterion(y_pred, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss.append(loss.item())\n",
    "            \n",
    "        return running_loss            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba9abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# ANGLE APPROACH\n",
    "class AngleDataSet(Dataset):\n",
    "    def __init__(self, annotation_file, img_dir, transform=None):\n",
    "        \n",
    "        self.labels = pd.read_csv(annotation_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video, frame_id = self.labels.iloc[idx, [0, 1]]\n",
    "        headx = self.labels.iloc[idx, 8]\n",
    "        heady = self.labels.iloc[idx, 9]\n",
    "        bodyx = self.labels.iloc[idx, 11]\n",
    "        bodyy = self.labels.iloc[idx, 12]\n",
    "        \n",
    "        l = ((headx - bodyx)**2 + (heady - bodyy)**2)**0.5\n",
    "        sina = (heady - bodyy)/l\n",
    "        cosa = (headx - bodyx)/l\n",
    "        \n",
    "        filename = '{}_{}'.format(video, frame_id)\n",
    "        img_path = os.path.join(self.img_dir, '{}.jpg'.format(filename))\n",
    "        image = io.read_image(img_path)\n",
    "        if self.transform != None:\n",
    "            image = self.transform(image).float()\n",
    "            \n",
    "        return image, torch.tensor([sina, cosa]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c2b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'TrainDataset/images'\n",
    "annotation_train = 'TrainDataset/train.csv'\n",
    "annotation_test = 'TrainDataset/test.csv'\n",
    "input_transform = transforms.Resize((224, 224))\n",
    "\n",
    "train_dataset = AngleDataSet(annotation_train, img_dir, input_transform)\n",
    "test_dataset = AngleDataSet(annotation_test, img_dir, input_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcec9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=40, shuffle=True, drop_last=True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size=40, shuffle=True, drop_last=True)\n",
    "model = ModResNet18(out_features=2, custom_classifier=True)\n",
    "criterion = nn.L1Loss()\n",
    "writer = SummaryWriter('./runs/AngApproach1/run_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab3bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ANNTrainer('MRS_Angle', model=model, train_loader=train_loader,\n",
    "                     validation_loader=validation_loader, criterion=criterion,\n",
    "                     writer=writer, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26656d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.find_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a9fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.assign_lr(10**-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d298d580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb800190d8444c9928e02839945a3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a5f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing down angular difference between the predicted and actual orientation\n",
    "\n",
    "get_angle = lambda x: np.angle(x[:, 0] + 1j*x[:, 1])\n",
    "angular_differences = np.empty(0)\n",
    "\n",
    "eval_model = ModResNet18(out_features=2, custom_classifier=True)\n",
    "eval_model.load_state_dict(torch.load('MRS_Angle_state_dict.pt'))\n",
    "eval_model.to('cpu')\n",
    "eval_model.eval()\n",
    "\n",
    "for x, y in validation_loader:\n",
    "    y_pred = eval_model(x)\n",
    "    y = get_angle(y.detach().numpy())\n",
    "    y_pred = get_angle(y_pred.detach().numpy())\n",
    "    angular_differences = np.append(angular_differences, y_pred - y)\n",
    "\n",
    "with open('angular_differences.csv', 'w') as inf:\n",
    "    for i in angular_differences:\n",
    "        inf.write(f'{i*180/np.pi}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
